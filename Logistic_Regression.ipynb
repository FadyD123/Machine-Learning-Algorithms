{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3jHY6DuvMeEgAT8WLsNNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FadyD123/Machine-Learning-Algorithms/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTc2gEwdqKVW"
      },
      "source": [
        "# Step 1: Import packages, functions, and classes\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 2: Get data\n",
        "x = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Step 3: Create a model and train it\n",
        "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)\n",
        "model.fit(x, y)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "p_pred = model.predict_proba(x)\n",
        "y_pred = model.predict(x)\n",
        "score_ = model.score(x, y)\n",
        "conf_m = confusion_matrix(y, y_pred)\n",
        "report = classification_report(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWahTFYp2bL5",
        "outputId": "12c3d917-3e71-4642-850e-2c8178e58162"
      },
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "\n",
        "Data_C = load_breast_cancer()\n",
        "\n",
        "x = Data_C.data\n",
        "\n",
        "BP = pd.DataFrame(x, columns = Data_C.feature_names)\n",
        "\n",
        "y = Data_C.target\n",
        "\n",
        "BP['y'] = y\n",
        "\n",
        "print(BP)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, train_size = 0.8, \n",
        "                                                    random_state = 88)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "Lr = LogisticRegression()\n",
        "\n",
        "Lr.fit(X_train, np.transpose(y_train))\n",
        "\n",
        "#y_pred = Lr.predict(X_test)\n",
        "\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "#acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Scores_NB = cross_val_score(Lr, x, y, cv = 10)\n",
        "\n",
        "#Scores_NB\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     mean radius  mean texture  ...  worst fractal dimension  y\n",
            "0          17.99         10.38  ...                  0.11890  0\n",
            "1          20.57         17.77  ...                  0.08902  0\n",
            "2          19.69         21.25  ...                  0.08758  0\n",
            "3          11.42         20.38  ...                  0.17300  0\n",
            "4          20.29         14.34  ...                  0.07678  0\n",
            "..           ...           ...  ...                      ... ..\n",
            "564        21.56         22.39  ...                  0.07115  0\n",
            "565        20.13         28.25  ...                  0.06637  0\n",
            "566        16.60         28.08  ...                  0.07820  0\n",
            "567        20.60         29.33  ...                  0.12400  0\n",
            "568         7.76         24.54  ...                  0.07039  1\n",
            "\n",
            "[569 rows x 31 columns]\n",
            "[[1.351e+01 1.889e+01 8.810e+01 ... 1.453e-01 2.666e-01 7.686e-02]\n",
            " [1.194e+01 2.076e+01 7.787e+01 ... 1.155e-01 2.465e-01 9.981e-02]\n",
            " [1.285e+01 2.137e+01 8.263e+01 ... 5.601e-02 2.488e-01 8.151e-02]\n",
            " ...\n",
            " [1.276e+01 1.884e+01 8.187e+01 ... 8.312e-02 2.744e-01 7.238e-02]\n",
            " [1.882e+01 2.197e+01 1.237e+02 ... 1.708e-01 3.007e-01 8.314e-02]\n",
            " [1.126e+01 1.996e+01 7.372e+01 ... 9.314e-02 2.955e-01 7.009e-02]]\n",
            "[1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
            " 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1\n",
            " 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1\n",
            " 1 1 1 1 0 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}